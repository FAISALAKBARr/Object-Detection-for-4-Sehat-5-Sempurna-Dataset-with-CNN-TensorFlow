{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Dataset paths\n",
    "base_dir = '/kaggle/input/data-4-sehat-5-sempurna/Dataset'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validasi')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Print dataset distribution\n",
    "def print_dataset_info():\n",
    "    categories = ['karbohidrat', 'protein', 'buah', 'sayur', 'minuman']\n",
    "    for split, directory in [('Training', train_dir), ('Validation', validation_dir), ('Test', test_dir)]:\n",
    "        print(f\"\\n{split} Dataset Distribution:\")\n",
    "        total = 0\n",
    "        for category in categories:\n",
    "            path = os.path.join(directory, category)\n",
    "            count = len(os.listdir(path)) if os.path.exists(path) else 0\n",
    "            total += count\n",
    "            print(f'{category}: {count} images')\n",
    "        print(f'Total: {total} images')\n",
    "\n",
    "print_dataset_info()\n",
    "\n",
    "# Enhanced Data Augmentation with more aggressive transformations\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    shear_range=0.2,\n",
    "    channel_shift_range=0.2,\n",
    "    preprocessing_function=lambda x: tf.image.random_contrast(x, 0.7, 1.3)\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Increased image size and adjusted batch size\n",
    "IMG_SIZE = 256  # Increased from 224\n",
    "BATCH_SIZE = 32 # Increased for better stability\n",
    "\n",
    "# Create generators with class balancing\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Modified Early Stopping Callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    min_delta=0.001\n",
    ")\n",
    "\n",
    "# Modified Learning Rate Schedule\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Improved CNN Architecture with Residual Connections\n",
    "def create_improved_model():\n",
    "    inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    \n",
    "    # Initial Conv Block\n",
    "    x = tf.keras.layers.Conv2D(64, (7, 7), strides=2, padding='same')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    \n",
    "    # Residual Block 1\n",
    "    shortcut = x\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    shortcut = tf.keras.layers.Conv2D(128, (1, 1), padding='same')(shortcut)\n",
    "    x = tf.keras.layers.Add()([x, shortcut])\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(2)(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Residual Block 2\n",
    "    shortcut = x\n",
    "    x = tf.keras.layers.Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    shortcut = tf.keras.layers.Conv2D(256, (1, 1), padding='same')(shortcut)\n",
    "    x = tf.keras.layers.Add()([x, shortcut])\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(2)(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    \n",
    "    # Global Average Pooling and Dense Layers\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(512)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    outputs = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Create and compile model with mixed precision\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "model = create_improved_model()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "EPOCHS = 100\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# # Train model\n",
    "# EPOCHS = 100\n",
    "# history = model.fit(\n",
    "#     train_generator,\n",
    "#     epochs=EPOCHS,\n",
    "#     validation_data=validation_generator,\n",
    "#     callbacks=[early_stopping, reduce_lr],\n",
    "#     workers=4,\n",
    "#     use_multiprocessing=True\n",
    "# )\n",
    "\n",
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Accuracy plot\n",
    "    ax1.plot(history.history['accuracy'], label='Training')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Loss plot\n",
    "    ax2.plot(history.history['loss'], label='Training')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(model, generator, set_name=\"Test\"):\n",
    "    # Predictions\n",
    "    predictions = model.predict(generator, verbose=1)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "    y_true = generator.classes\n",
    "    \n",
    "    # Get class names\n",
    "    class_names = list(generator.class_indices.keys())\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names,\n",
    "                yticklabels=class_names)\n",
    "    plt.title(f'Confusion Matrix ({set_name} Set)')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification Report\n",
    "    print(f\"\\nClassification Report ({set_name} Set):\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "    \n",
    "    # Overall Metrics\n",
    "    loss, accuracy = model.evaluate(generator, verbose=0)\n",
    "    print(f\"\\n{set_name} Set Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{set_name} Set Loss: {loss:.4f}\")\n",
    "\n",
    "# Evaluate on validation and test sets\n",
    "# print(\"\\Train Set Evaluation:\")\n",
    "# evaluate_model(model, train_generator, \"Train\")\n",
    "\n",
    "print(\"\\nValidation Set Evaluation:\")\n",
    "evaluate_model(model, validation_generator, \"Validation\")\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "evaluate_model(model, test_generator, \"Test\")\n",
    "\n",
    "# Save model and history\n",
    "model.save('/kaggle/working/model.h5')\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv('/kaggle/working/training_history.csv')\n",
    "print(\"\\nModel and training history saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
